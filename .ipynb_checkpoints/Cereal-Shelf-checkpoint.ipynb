{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "- For everybody to be able to follow along and learn something\n",
    "- Use vanilla python with standard libraries only when needed\n",
    "\n",
    "## Disclamers\n",
    "- Not necessarily the best way or even the right way\n",
    "- \n",
    "\n",
    "API key:\n",
    "kqA964yzjSblTKwZ3Fa9z3GMU8rCZO4fLVXTrZuu\n",
    "example: https://developer.nrel.gov/api/alt-fuel-stations/v1/nearest.json?api_key=kqA964yzjSblTKwZ3Fa9z3GMU8rCZO4fLVXTrZuu&location=Denver+CO\n",
    "\n",
    "Helpful links: \n",
    "- http://nymag.com/restaurants/features/breakfast/47390/index1.html\n",
    "- http://www.asaurus.net/~buhr/academic/2004-2-ubc-stat445/projects/project1-sample-2.pdf\n",
    "- http://www.lavasurfer.com/boxtop/boxtop-cerealratings.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Prepare our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CSV into our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name: Name of cereal\n",
    "- mfr: Manufacturer of cereal\n",
    "    - A = American Home Food Products;\n",
    "    - G = General Mills\n",
    "    - K = Kelloggs\n",
    "    - N = Nabisco\n",
    "    - P = Post\n",
    "    - Q = Quaker Oats\n",
    "    - R = Ralston Purina\n",
    "- type: cold vs hot\n",
    "- calories: calories per serving\n",
    "- protein: grams of protein\n",
    "- fat: grams of fat\n",
    "- sodium: milligrams of sodium\n",
    "- fiber: grams of dietary fiber\n",
    "- carbo: grams of complex carbohydrates\n",
    "- sugars: grams of sugars\n",
    "- potass: milligrams of potassium\n",
    "- vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended serving\n",
    "- shelf: display shelf (1, 2, or 3, counting from the floor)\n",
    "- weight: weight in ounces of one serving\n",
    "- cups: number of cups in one serving\n",
    "- rating: a rating of the cereals (Possibly from Consumer Reports?)\n",
    "\n",
    "Source: https://www.kaggle.com/crawford/80-cereals\n",
    "\n",
    "[View this File](/edit/cereal.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name', 'mfr', 'type', 'calories', 'protein', 'fat', 'sodium', 'fiber', 'carbo', 'sugars', 'potass', 'vitamins', 'shelf', 'weight', 'cups', 'rating'], ['100% Bran', 'N', 'C', '70', '4', '1', '130', '10', '5', '6', '280', '25', '3', '1', '0.33', '68.402973'], ['100% Natural Bran', 'Q', 'C', '120', '3', '5', '15', '2', '8', '8', '135', '0', '3', '1', '1', '33.983679'], ['All-Bran', 'K', 'C', '70', '4', '1', '260', '9', '7', '5', '320', '25', '3', '1', '0.33', '59.425505'], ['All-Bran with Extra Fiber', 'K', 'C', '50', '4', '0', '140', '14', '8', '0', '330', '25', '3', '1', '0.5', '93.704912'], ['Almond Delight', 'R', 'C', '110', '2', '2', '200', '1', '14', '8', '0', '25', '3', '1', '0.75', '34.384843'], ['Apple Cinnamon Cheerios', 'G', 'C', '110', '2', '2', '180', '1.5', '10.5', '10', '70', '25', '1', '1', '0.75', '29.509541'], ['Apple Jacks', 'K', 'C', '110', '2', '0', '125', '1', '11', '14', '30', '25', '2', '1', '1', '33.174094'], ['Basic 4', 'G', 'C', '130', '3', '2', '210', '2', '18', '8', '100', '25', '3', '1.33', '0.75', '37.038562'], ['Bran Chex', 'R', 'C', '90', '2', '1', '200', '4', '15', '6', '125', '25', '1', '1', '0.67', '49.120253'], ['Bran Flakes', 'P', 'C', '90', '3', '0', '210', '5', '13', '5', '190', '25', '3', '1', '0.67', '53.313813'], [\"Cap'n'Crunch\", 'Q', 'C', '120', '1', '2', '220', '0', '12', '12', '35', '25', '2', '1', '0.75', '18.042851'], ['Cheerios', 'G', 'C', '110', '6', '2', '290', '2', '17', '1', '105', '25', '1', '1', '1.25', '50.764999'], ['Cinnamon Toast Crunch', 'G', 'C', '120', '1', '3', '210', '0', '13', '9', '45', '25', '2', '1', '0.75', '19.823573'], ['Clusters', 'G', 'C', '110', '3', '2', '140', '2', '13', '7', '105', '25', '3', '1', '0.5', '40.400208'], ['Cocoa Puffs', 'G', 'C', '110', '1', '1', '180', '0', '12', '13', '55', '25', '2', '1', '1', '22.736446'], ['Corn Chex', 'R', 'C', '110', '2', '0', '280', '0', '22', '3', '25', '25', '1', '1', '1', '41.445019'], ['Corn Flakes', 'K', 'C', '100', '2', '0', '290', '1', '21', '2', '35', '25', '1', '1', '1', '45.863324'], ['Corn Pops', 'K', 'C', '110', '1', '0', '90', '1', '13', '12', '20', '25', '2', '1', '1', '35.782791'], ['Count Chocula', 'G', 'C', '110', '1', '1', '180', '0', '12', '13', '65', '25', '2', '1', '1', '22.396513'], [\"Cracklin' Oat Bran\", 'K', 'C', '110', '3', '3', '140', '4', '10', '7', '160', '25', '3', '1', '0.5', '40.448772'], ['Cream of Wheat (Quick)', 'N', 'H', '100', '3', '0', '80', '1', '21', '0', '0', '0', '2', '1', '1', '64.533816'], ['Crispix', 'K', 'C', '110', '2', '0', '220', '1', '21', '3', '30', '25', '3', '1', '1', '46.895644'], ['Crispy Wheat & Raisins', 'G', 'C', '100', '2', '1', '140', '2', '11', '10', '120', '25', '3', '1', '0.75', '36.176196'], ['Double Chex', 'R', 'C', '100', '2', '0', '190', '1', '18', '5', '80', '25', '3', '1', '0.75', '44.330856'], ['Froot Loops', 'K', 'C', '110', '2', '1', '125', '1', '11', '13', '30', '25', '2', '1', '1', '32.207582'], ['Frosted Flakes', 'K', 'C', '110', '1', '0', '200', '1', '14', '11', '25', '25', '1', '1', '0.75', '31.435973'], ['Frosted Mini-Wheats', 'K', 'C', '100', '3', '0', '0', '3', '14', '7', '100', '25', '2', '1', '0.8', '58.345141'], ['Fruit & Fibre Dates; Walnuts; and Oats', 'P', 'C', '120', '3', '2', '160', '5', '12', '10', '200', '25', '3', '1.25', '0.67', '40.917047'], ['Fruitful Bran', 'K', 'C', '120', '3', '0', '240', '5', '14', '12', '190', '25', '3', '1.33', '0.67', '41.015492'], ['Fruity Pebbles', 'P', 'C', '110', '1', '1', '135', '0', '13', '12', '25', '25', '2', '1', '0.75', '28.025765'], ['Golden Crisp', 'P', 'C', '100', '2', '0', '45', '0', '11', '15', '40', '25', '1', '1', '0.88', '35.252444'], ['Golden Grahams', 'G', 'C', '110', '1', '1', '280', '0', '15', '9', '45', '25', '2', '1', '0.75', '23.804043'], ['Grape Nuts Flakes', 'P', 'C', '100', '3', '1', '140', '3', '15', '5', '85', '25', '3', '1', '0.88', '52.076897'], ['Grape-Nuts', 'P', 'C', '110', '3', '0', '170', '3', '17', '3', '90', '25', '3', '1', '0.25', '53.371007'], ['Great Grains Pecan', 'P', 'C', '120', '3', '3', '75', '3', '13', '4', '100', '25', '3', '1', '0.33', '45.811716'], ['Honey Graham Ohs', 'Q', 'C', '120', '1', '2', '220', '1', '12', '11', '45', '25', '2', '1', '1', '21.871292'], ['Honey Nut Cheerios', 'G', 'C', '110', '3', '1', '250', '1.5', '11.5', '10', '90', '25', '1', '1', '0.75', '31.072217'], ['Honey-comb', 'P', 'C', '110', '1', '0', '180', '0', '14', '11', '35', '25', '1', '1', '1.33', '28.742414'], ['Just Right Crunchy  Nuggets', 'K', 'C', '110', '2', '1', '170', '1', '17', '6', '60', '100', '3', '1', '1', '36.523683'], ['Just Right Fruit & Nut', 'K', 'C', '140', '3', '1', '170', '2', '20', '9', '95', '100', '3', '1.3', '0.75', '36.471512'], ['Kix', 'G', 'C', '110', '2', '1', '260', '0', '21', '3', '40', '25', '2', '1', '1.5', '39.241114'], ['Life', 'Q', 'C', '100', '4', '2', '150', '2', '12', '6', '95', '25', '2', '1', '0.67', '45.328074'], ['Lucky Charms', 'G', 'C', '110', '2', '1', '180', '0', '12', '12', '55', '25', '2', '1', '1', '26.734515'], ['Maypo', 'A', 'H', '100', '4', '1', '0', '0', '16', '3', '95', '25', '2', '1', '1', '54.850917'], ['Muesli Raisins; Dates; & Almonds', 'R', 'C', '150', '4', '3', '95', '3', '16', '11', '170', '25', '3', '1', '1', '37.136863'], ['Muesli Raisins; Peaches; & Pecans', 'R', 'C', '150', '4', '3', '150', '3', '16', '11', '170', '25', '3', '1', '1', '34.139765'], ['Mueslix Crispy Blend', 'K', 'C', '160', '3', '2', '150', '3', '17', '13', '160', '25', '3', '1.5', '0.67', '30.313351'], ['Multi-Grain Cheerios', 'G', 'C', '100', '2', '1', '220', '2', '15', '6', '90', '25', '1', '1', '1', '40.105965'], ['Nut&Honey Crunch', 'K', 'C', '120', '2', '1', '190', '0', '15', '9', '40', '25', '2', '1', '0.67', '29.924285'], ['Nutri-Grain Almond-Raisin', 'K', 'C', '140', '3', '2', '220', '3', '21', '7', '130', '25', '3', '1.33', '0.67', '40.69232'], ['Nutri-grain Wheat', 'K', 'C', '90', '3', '0', '170', '3', '18', '2', '90', '25', '3', '1', '1', '59.642837'], ['Oatmeal Raisin Crisp', 'G', 'C', '130', '3', '2', '170', '1.5', '13.5', '10', '120', '25', '3', '1.25', '0.5', '30.450843'], ['Post Nat. Raisin Bran', 'P', 'C', '120', '3', '1', '200', '6', '11', '14', '260', '25', '3', '1.33', '0.67', '37.840594'], ['Product 19', 'K', 'C', '100', '3', '0', '320', '1', '20', '3', '45', '100', '3', '1', '1', '41.50354'], ['Puffed Rice', 'Q', 'C', '50', '1', '0', '0', '0', '13', '0', '15', '0', '3', '0.5', '1', '60.756112'], ['Puffed Wheat', 'Q', 'C', '50', '2', '0', '0', '1', '10', '0', '50', '0', '3', '0.5', '1', '63.005645'], ['Quaker Oat Squares', 'Q', 'C', '100', '4', '1', '135', '2', '14', '6', '110', '25', '3', '1', '0.5', '49.511874'], ['Quaker Oatmeal', 'Q', 'H', '100', '5', '2', '0', '2.7', '-1', '-1', '110', '0', '1', '1', '0.67', '50.828392'], ['Raisin Bran', 'K', 'C', '120', '3', '1', '210', '5', '14', '12', '240', '25', '2', '1.33', '0.75', '39.259197'], ['Raisin Nut Bran', 'G', 'C', '100', '3', '2', '140', '2.5', '10.5', '8', '140', '25', '3', '1', '0.5', '39.7034'], ['Raisin Squares', 'K', 'C', '90', '2', '0', '0', '2', '15', '6', '110', '25', '3', '1', '0.5', '55.333142'], ['Rice Chex', 'R', 'C', '110', '1', '0', '240', '0', '23', '2', '30', '25', '1', '1', '1.13', '41.998933'], ['Rice Krispies', 'K', 'C', '110', '2', '0', '290', '0', '22', '3', '35', '25', '1', '1', '1', '40.560159'], ['Shredded Wheat', 'N', 'C', '80', '2', '0', '0', '3', '16', '0', '95', '0', '1', '0.83', '1', '68.235885'], [\"Shredded Wheat 'n'Bran\", 'N', 'C', '90', '3', '0', '0', '4', '19', '0', '140', '0', '1', '1', '0.67', '74.472949'], ['Shredded Wheat spoon size', 'N', 'C', '90', '3', '0', '0', '3', '20', '0', '120', '0', '1', '1', '0.67', '72.801787'], ['Smacks', 'K', 'C', '110', '2', '1', '70', '1', '9', '15', '40', '25', '2', '1', '0.75', '31.230054'], ['Special K', 'K', 'C', '110', '6', '0', '230', '1', '16', '3', '55', '25', '1', '1', '1', '53.131324'], ['Strawberry Fruit Wheats', 'N', 'C', '90', '2', '0', '15', '3', '15', '5', '90', '25', '2', '1', '1', '59.363993'], ['Total Corn Flakes', 'G', 'C', '110', '2', '1', '200', '0', '21', '3', '35', '100', '3', '1', '1', '38.839746'], ['Total Raisin Bran', 'G', 'C', '140', '3', '1', '190', '4', '15', '14', '230', '100', '3', '1.5', '1', '28.592785'], ['Total Whole Grain', 'G', 'C', '100', '3', '1', '200', '3', '16', '3', '110', '100', '3', '1', '1', '46.658844'], ['Triples', 'G', 'C', '110', '2', '1', '250', '0', '21', '3', '60', '25', '3', '1', '0.75', '39.106174'], ['Trix', 'G', 'C', '110', '1', '1', '140', '0', '13', '12', '25', '25', '2', '1', '1', '27.753301'], ['Wheat Chex', 'R', 'C', '100', '3', '1', '230', '3', '17', '3', '115', '25', '1', '1', '0.67', '49.787445'], ['Wheaties', 'G', 'C', '100', '3', '1', '200', '3', '17', '3', '110', '25', '1', '1', '1', '51.592193'], ['Wheaties Honey Gold', 'G', 'C', '110', '2', '1', '200', '1', '16', '8', '60', '25', '1', '1', '0.75', '36.187559']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('cereal.csv') as f:\n",
    "    data = list(csv.reader(f))\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  78\n",
      "Number of Cols:  16\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows: ', len(data))\n",
    "print('Number of Cols: ', len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name   mfr    type   calori protei fat    sodium fiber  carbo  sugars potass vitami shelf  weight cups   rating \n",
      "\n",
      "100% B N      C      70     4      1      130    10     5      6      280    25     3      1      0.33   68.402 \n",
      "\n",
      "100% N Q      C      120    3      5      15     2      8      8      135    0      3      1      1      33.983 \n",
      "\n",
      "All-Br K      C      70     4      1      260    9      7      5      320    25     3      1      0.33   59.425 \n",
      "\n",
      "All-Br K      C      50     4      0      140    14     8      0      330    25     3      1      0.5    93.704 \n",
      "\n",
      "Almond R      C      110    2      2      200    1      14     8      0      25     3      1      0.75   34.384 \n",
      "\n",
      "** Total Number of columns:  16\n",
      "** Displaying rows 1 -  6  of  78 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def peak_in(d, rows=6):\n",
    "    for row in d[0:rows]:\n",
    "        for col_num, col in enumerate(row):\n",
    "            if (col_num <= 15):\n",
    "                print(str(col)[:6], end=(' ' * (7 - len(str(col)[:6]))))\n",
    "            else:\n",
    "                print(' ... ')\n",
    "                break\n",
    "        print('\\n')\n",
    "\n",
    "    print('** Total Number of columns: ', str(len(data[0])))\n",
    "    print('** Displaying rows 1 - ', str(rows), ' of ', str(len(d)), '\\n')\n",
    "\n",
    "peak_in(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Randomize Our Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% B N      C      70     4      1      130    10     5      6      280    25     3      1      0.33   68.402 \n",
      "\n",
      "100% N Q      C      120    3      5      15     2      8      8      135    0      3      1      1      33.983 \n",
      "\n",
      "All-Br K      C      70     4      1      260    9      7      5      320    25     3      1      0.33   59.425 \n",
      "\n",
      "All-Br K      C      50     4      0      140    14     8      0      330    25     3      1      0.5    93.704 \n",
      "\n",
      "Almond R      C      110    2      2      200    1      14     8      0      25     3      1      0.75   34.384 \n",
      "\n",
      "Apple  G      C      110    2      2      180    1.5    10.5   10     70     25     1      1      0.75   29.509 \n",
      "\n",
      "** Total Number of columns:  16\n",
      "** Displaying rows 1 -  6  of  77 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_randomized = data[1:]\n",
    "# commenting this because I want to keep the headers where they are\n",
    "# data_randomized = data\n",
    "import random\n",
    "# random.shuffle(data_randomized);\n",
    "# commenting this because I want to keep things simple for now\n",
    "\n",
    "peak_in(data_randomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0   4.0    1.0    130.0  10.0   5.0    6.0    280.0  25.0   3.0    1.0    0.33   \n",
      "\n",
      "120.0  3.0    5.0    15.0   2.0    8.0    8.0    135.0  0.0    3.0    1.0    1.0    \n",
      "\n",
      "70.0   4.0    1.0    260.0  9.0    7.0    5.0    320.0  25.0   3.0    1.0    0.33   \n",
      "\n",
      "50.0   4.0    0.0    140.0  14.0   8.0    0.0    330.0  25.0   3.0    1.0    0.5    \n",
      "\n",
      "110.0  2.0    2.0    200.0  1.0    14.0   8.0    0.0    25.0   3.0    1.0    0.75   \n",
      "\n",
      "110.0  2.0    2.0    180.0  1.5    10.5   10.0   70.0   25.0   1.0    1.0    0.75   \n",
      "\n",
      "** Total Number of columns:  16\n",
      "** Displaying rows 1 -  6  of  77 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_values_only = []\n",
    "\n",
    "for row_num, row in enumerate(data_randomized):\n",
    "    data_values_only.append([])\n",
    "    for col_num, col in enumerate(row):\n",
    "        if (col_num not in {0, 1, 2, 15}):\n",
    "            data_values_only[row_num].append(float(col))\n",
    "            \n",
    "peak_in(data_values_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names for reference:\n",
    "\n",
    "## this is how far I got\n",
    "\n",
    "\n",
    "(0) Cals | (1) Prot | (2) Fat | (3) Na | (4) Fib | (5) Carb | (6) Sug | (7) K  | (8) Vit | (9) Shelf | (10)  Weight | (11) Cups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proportional = [];\n",
    "\n",
    "for row_num, row in enumerate(data_values_only):\n",
    "    data_proportional.append([])\n",
    "    for col_num, col in enumerate(row):\n",
    "        if (col_num not in {9, 11}):\n",
    "            data_proportional[row_num].append(col / data_values_only[row_num][9])\n",
    "        elif (col_num == 11):\n",
    "            data_proportional[row_num].append(col) # Score, unchanged\n",
    "\n",
    "peak_in(data_proportional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names for reference:\n",
    "(0) Cals | (1) Prot | (2) Fat | (3) Na | (4) Fib | (5) Carb | (6) Sug | (7) K | (8) Vit | (9) Weight | (10) Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Y-Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepped = [];\n",
    "\n",
    "for row_num, row in enumerate(data_proportional):\n",
    "    data_prepped.append([1] + data_proportional[row_num])\n",
    "            \n",
    "peak_in(data_prepped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Our Data into two parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Labels for Reference\n",
    "\n",
    "(0) Y-int | (1) Cals | (2) Prot | (3) Fat | (4) Na | (5) Fib | (6) Carb | (7) Sug | (8) K | (9) Vit | (10) Weight | (11) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_training_examples = int(len(data_prepped)*0.8)\n",
    "\n",
    "training_set   = data_prepped[:num_of_training_examples]\n",
    "validation_set = data_prepped[num_of_training_examples:]\n",
    "\n",
    "print('Number of training examples: ' + str(len(training_set)))\n",
    "print('Number of validation examples: ' + str(len(validation_set)))\n",
    "print('Number of features: ', len(validation_set[0]) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create Our Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Our Parameters For Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in training_set:\n",
    "    X.append(row[:11])\n",
    "    y.append(row[11])\n",
    "    \n",
    "m = len(X)\n",
    "theta = [0] * m\n",
    "alpha = 0.3\n",
    "iterations = 5\n",
    "\n",
    "print('X (Sample): ')\n",
    "peak_in(X)\n",
    "print('---\\n')\n",
    "print('y: ', y, '\\n\\n---\\n')\n",
    "print('m: ', m, '\\n\\n---\\n')\n",
    "print('theta: ', theta, '\\n\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(matrix):\n",
    "    return list(map(list, zip(*matrix)))\n",
    "\n",
    "example_matrix = [[1,2,3],\n",
    "                  [4,5,6],\n",
    "                  [7,8,9]]\n",
    "\n",
    "peak_in(transpose(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize All the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refresher of statistics terms:\n",
    "\n",
    "- **μ or mu:** The mean (i.e. average) of a list of values.  \n",
    "\n",
    "- **σ or sigma or standard deviation:** A measure of how dispersed a data set is from it's mean.\n",
    "\n",
    "- **range**: Difference between the highest and lowest item in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "peak_in(X)\n",
    "\n",
    "# returns a list of means for each feature (the number of features)\n",
    "mu = list(map(statistics.mean,transpose(X)))\n",
    "\n",
    "# returns list of ranges for each feature\n",
    "print(transpose(X)[1])\n",
    "\n",
    "X_range = list(map(lambda feature: max(feature) - min(feature), transpose(X))) \n",
    "\n",
    "# returns a normalized version of X\n",
    "def normalize(X):\n",
    "    normalized_X = []\n",
    "    for row_num, row in enumerate(X):\n",
    "        normalized_X.append([])\n",
    "        for col_num in range(len(row)):\n",
    "            if (col_num == 0): # y-intercept does not need normalization\n",
    "                normalized_X[row_num].append(row[col_num])\n",
    "            else:\n",
    "                normalized_X[row_num].append(\n",
    "                    (row[col_num] - mu[col_num]) / X_range[col_num]\n",
    "                )\n",
    "    return normalized_X\n",
    "\n",
    "X_norm = normalize(X)\n",
    "\n",
    "print('mu:', mu, '\\n')\n",
    "print('range:', X_range, '\\n')\n",
    "print('Normalized X:')\n",
    "peak_in(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J(θ1)=12m∑i=1m(hθ(x(i))−y(i))2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(theta, X_row):\n",
    "    # X_row = a single row of X...  \n",
    "    # theta = all theta values... currently [0, 0, 0, ... 0]\n",
    "    return sum([theta*column for theta, column in zip(X_row, theta)])\n",
    "\n",
    "def individual_trial_error(theta, X_row, correct_answer):\n",
    "    # correct_answer = the corresponding y value for the current X_row\n",
    "    return hypothesis(theta, X_row) - correct_answer\n",
    "\n",
    "print (individual_trial_error(theta, X_norm[1], y[1]))\n",
    "theta = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "def all_errors(theta, X, correct_answers):\n",
    "    # X = all rows of X\n",
    "    # theta = all theta values\n",
    "    # correct_answers = all y values for all rows of X\n",
    "    return [individual_trial_error(theta, X[row], y[row]) for row in range(len(X))]\n",
    "\n",
    "\n",
    "print ('all_errors', all_errors(theta, X, y))\n",
    "    \n",
    "def squared_error(theta, X, correct_answers):\n",
    "    return sum([individual_trial_error(theta, X[row], y[row])**2 for row in range(len(X))])\n",
    "\n",
    "# Our goal is to reduce this!\n",
    "def loss_function(theta, X, correct_answers, m):\n",
    "    return (1/(2*m))*squared_error(theta, X, correct_answers)\n",
    "\n",
    "print(loss_function(theta, X_norm, y, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Apply Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def partial_derivative_of_loss_function(theta, X, y, col):\n",
    "#     print('losing it: ', print(all_errors(theta, X_norm, y)[0]))\n",
    "#     print('printing this:')\n",
    "#     print(X[2][1])\n",
    "#     print('will I figure it out')\n",
    "#     print([all_errors(theta, X_norm, y)[row]*X[row][col] for row in range(len(X))])\n",
    "#     print('\\n\\n')\n",
    "#     print('all_errors:', all_errors(theta, X_norm, y))\n",
    "#     print('\\n\\n')\n",
    "#     print ('before the sum: ', [all_errors(theta, X_norm, y)[row]*X[row][col] for row in range(len(X))])\n",
    "#     print('partial derivative: ', sum([all_errors(theta, X_norm, y)[row]*X[row][col] for row in range(len(X))]))\n",
    "    return sum([all_errors(theta, X_norm, y)[row]*X[row][col] for row in range(len(X))])\n",
    "\n",
    "\n",
    "\n",
    "def gradient_descent(theta, X, y, alpha, m):\n",
    "    new_theta = []\n",
    "#     print('theta before:', theta)\n",
    "#     print('alpha*1/m', alpha*(1/m))\n",
    "#     print('m', m)\n",
    "    for theta_index, theta_value in enumerate(theta):\n",
    "        new_theta.append(theta_value)\n",
    "        new_theta[theta_index] = theta_value - (alpha*(1/m)*partial_derivative_of_loss_function(theta, X, y, theta_index))\n",
    "\n",
    "    return new_theta\n",
    "\n",
    "\n",
    "# theta = gradient_descent(theta, X_norm, y, alpha, m)\n",
    "# print('finally...theta is:', some_theta)\n",
    "# print('these should be old:', theta)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# gradient_descent(X_norm, theta, y)\n",
    "# print(gradient_descent(X_norm, theta, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    theta = gradient_descent(theta, X_norm, y, alpha, m)\n",
    "    print(loss_function(theta, X_norm, y, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Test Our Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_in(validation_set)\n",
    "\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "\n",
    "print('optom theta', theta)\n",
    "\n",
    "for row in validation_set:\n",
    "    X_validation.append(row[:11])\n",
    "    y_validation.append(row[11])\n",
    "    \n",
    "X_validation_norm = normalize(X_validation)\n",
    "\n",
    "peak_in(X_validation_norm)\n",
    "\n",
    "print('yvalidation: ', y_validation)\n",
    "\n",
    "print('predicted ', 'actual   ', 'difference')\n",
    "for row_num, row in enumerate(X_validation_norm):\n",
    "    predicted_score = hypothesis(theta, X_validation_norm[row_num])\n",
    "    actual_score = y_validation[row_num]\n",
    "    difference = predicted_score - actual_score\n",
    "    print(str(predicted_score)[:6], '   ',\n",
    "          str(actual_score)[:6], '  ', \n",
    "          str(difference)[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it in 5 lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 13)\n",
      "[3. 3. 3. 3. 3. 1. 2. 3. 1. 3. 2. 1. 2. 3. 2. 1. 1. 2. 2. 3. 2. 3. 3. 3.\n",
      " 2. 1. 2. 3. 3. 2. 1. 2. 3. 3. 3. 2. 1. 1. 3. 3. 2. 2. 2. 2. 3. 3. 3. 1.\n",
      " 2. 3. 3. 3. 3. 3. 3. 3. 3. 1. 2. 3. 3. 1. 1. 1. 1. 1. 2. 1. 2. 3. 3. 3.\n",
      " 3. 2. 1. 1. 1.]\n",
      "(77, 9)\n",
      "[[110.    1.    1.  280.    0.   15.    9.   45.   25. ]\n",
      " [160.    3.    2.  150.    3.   17.   13.  160.   25. ]\n",
      " [100.    3.    1.  140.    3.   15.    5.   85.   25. ]\n",
      " [130.    3.    2.  210.    2.   18.    8.  100.   25. ]\n",
      " [ 90.    2.    0.   15.    3.   15.    5.   90.   25. ]\n",
      " [ 90.    3.    0.    0.    3.   20.    0.  120.    0. ]\n",
      " [100.    3.    0.    0.    3.   14.    7.  100.   25. ]\n",
      " [100.    3.    1.  230.    3.   17.    3.  115.   25. ]\n",
      " [110.    1.    0.  180.    0.   14.   11.   35.   25. ]\n",
      " [140.    3.    1.  170.    2.   20.    9.   95.  100. ]\n",
      " [110.    3.    2.  140.    2.   13.    7.  105.   25. ]\n",
      " [110.    1.    0.  200.    1.   14.   11.   25.   25. ]\n",
      " [120.    1.    2.  220.    0.   12.   12.   35.   25. ]\n",
      " [110.    2.    0.  220.    1.   21.    3.   30.   25. ]\n",
      " [130.    3.    2.  170.    1.5  13.5  10.  120.   25. ]\n",
      " [110.    2.    1.   70.    1.    9.   15.   40.   25. ]\n",
      " [100.    3.    2.  140.    2.5  10.5   8.  140.   25. ]\n",
      " [110.    1.    0.   90.    1.   13.   12.   20.   25. ]\n",
      " [ 50.    1.    0.    0.    0.   13.    0.   15.    0. ]\n",
      " [110.    1.    1.  135.    0.   13.   12.   25.   25. ]\n",
      " [100.    2.    0.   45.    0.   11.   15.   40.   25. ]\n",
      " [110.    2.    1.  125.    1.   11.   13.   30.   25. ]\n",
      " [100.    2.    1.  220.    2.   15.    6.   90.   25. ]\n",
      " [ 70.    4.    1.  260.    9.    7.    5.  320.   25. ]\n",
      " [100.    4.    1.    0.    0.   16.    3.   95.   25. ]\n",
      " [ 90.    3.    0.    0.    4.   19.    0.  140.    0. ]\n",
      " [110.    3.    1.  250.    1.5  11.5  10.   90.   25. ]\n",
      " [120.    3.    5.   15.    2.    8.    8.  135.    0. ]\n",
      " [ 90.    3.    0.  210.    5.   13.    5.  190.   25. ]\n",
      " [110.    1.    1.  180.    0.   12.   13.   55.   25. ]\n",
      " [120.    1.    3.  210.    0.   13.    9.   45.   25. ]\n",
      " [110.    3.    0.  170.    3.   17.    3.   90.   25. ]\n",
      " [ 50.    4.    0.  140.   14.    8.    0.  330.   25. ]\n",
      " [110.    2.    0.  290.    0.   22.    3.   35.   25. ]\n",
      " [ 50.    2.    0.    0.    1.   10.    0.   50.    0. ]\n",
      " [110.    3.    3.  140.    4.   10.    7.  160.   25. ]\n",
      " [ 70.    4.    1.  130.   10.    5.    6.  280.   25. ]\n",
      " [110.    1.    1.  180.    0.   12.   13.   65.   25. ]\n",
      " [100.    2.    1.  140.    2.   11.   10.  120.   25. ]\n",
      " [110.    2.    1.  170.    1.   17.    6.   60.  100. ]\n",
      " [110.    1.    0.  240.    0.   23.    2.   30.   25. ]\n",
      " [ 80.    2.    0.    0.    3.   16.    0.   95.    0. ]\n",
      " [110.    2.    1.  250.    0.   21.    3.   60.   25. ]\n",
      " [ 90.    2.    1.  200.    4.   15.    6.  125.   25. ]\n",
      " [100.    5.    2.    0.    2.7  -1.   -1.  110.    0. ]\n",
      " [120.    1.    2.  220.    1.   12.   11.   45.   25. ]\n",
      " [100.    3.    1.  200.    3.   16.    3.  110.  100. ]\n",
      " [100.    4.    2.  150.    2.   12.    6.   95.   25. ]\n",
      " [110.    2.    2.  180.    1.5  10.5  10.   70.   25. ]\n",
      " [ 90.    2.    0.    0.    2.   15.    6.  110.   25. ]\n",
      " [100.    2.    0.  190.    1.   18.    5.   80.   25. ]\n",
      " [120.    2.    1.  190.    0.   15.    9.   40.   25. ]\n",
      " [110.    2.    1.  200.    0.   21.    3.   35.  100. ]\n",
      " [110.    1.    1.  140.    0.   13.   12.   25.   25. ]\n",
      " [120.    3.    3.   75.    3.   13.    4.  100.   25. ]\n",
      " [100.    4.    1.  135.    2.   14.    6.  110.   25. ]\n",
      " [100.    2.    0.  290.    1.   21.    2.   35.   25. ]]\n",
      "reg.coef_ [ 0.          0.          0.         -0.00105658 -0.         -0.\n",
      "  0.          0.00408914  0.0114832 ]\n",
      "predict [2. 3. 4. 3. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 3. 2. 2. 2. 2. 2.]\n",
      "actual [3. 3. 3. 3. 2. 2. 3. 3. 3. 2. 1. 3. 1. 3. 3. 1. 2. 1. 1. 2.]\n",
      "accuracy_rate: 0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, linear_model\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "data = numpy.genfromtxt('cereal.csv', delimiter=',')[1:,3:]\n",
    "# peak_in(data)\n",
    "\n",
    "# seperated_data = data[np.ix_([1:2], [1])]\n",
    "# print(seperated_data)\n",
    "\n",
    "# test = np.array([[1,2,3,4,5],[4,5,6,7,8],[7,8,9,10,12]])\n",
    "# print(test[:,1:3])\n",
    "# test2 = np.r_[test[:,1:3]]\n",
    "\n",
    "# print(test2)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "y = data[:, 9]\n",
    "print(y)\n",
    "X = data[:,:9]\n",
    "\n",
    "# print(X.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)\n",
    "\n",
    "# print(X_train)\n",
    "\n",
    "reg = linear_model.Lasso()\n",
    "reg.fit (X_train, y_train)\n",
    "\n",
    "predict = np.round_(reg.predict(X_test))\n",
    "actual = y_test\n",
    "\n",
    "print('reg.coef_', reg.coef_)\n",
    "print('predict', predict)\n",
    "print('actual', actual)\n",
    "\n",
    "total_correct = 0\n",
    "total_wrong = 0\n",
    "for guess_num in range(len(predict)):\n",
    "    if (predict[guess_num] == actual[guess_num]):\n",
    "        total_correct += 1\n",
    "    else:\n",
    "        total_wrong += 1\n",
    "\n",
    "print('accuracy_rate:', total_correct/(total_correct+total_wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
